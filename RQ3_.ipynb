{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYPPtQ+vq2VudQPQKPBZIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoodNightIsabel/Replication/blob/main/RQ3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "GKW8fhJ98Ppq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GSYqX4nI32Gn"
      },
      "outputs": [],
      "source": [
        "#loading the data\n",
        "Data1 = pd.read_csv('IST_MIR.csv')\n",
        "Data2 = pd.read_csv('IST_OST.csv')\n",
        "Data3 = pd.read_csv('IST_WIK.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "UFQLM6Fe_UMb",
        "outputId": "1386e58f-423b-482f-c72c-45333b0361ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [{\"payload\":{\"allShortcutsEnabled\":true, fileTree:{\"datasets\":{\"items\":[{\"name\":\"IST_MIR.csv\", path:\"datasets/IST_MIR.csv\", contentType:\"file\"}, {\"name\":\"IST_MOZ.csv\", path:\"datasets/IST_MOZ.csv\", contentType:\"file\"}.1, {\"name\":\"IST_OST.csv\", path:\"datasets/IST_OST.csv\", contentType:\"file\"}.2, {\"name\":\"IST_WIK.csv\", path:\"datasets/IST_WIK.csv\", contentType:\"file\"}.3, {\"name\":\"RQ 1 plots & tables.ipynb\", path:\"datasets/RQ 1 plots & tables.ipynb\", contentType:\"file\"}], totalCount:5}, :{\"items\":[{\"name\":\"datasets\", path:\"datasets\", contentType:\"directory\"}, {\"name\":\"repositories\", path:\"repositories\", contentType:\"directory\"}.1, {\"name\":\"repository_exploration\", path:\"repository_exploration\", contentType:\"directory\"}.2, {\"name\":\"README.md\", path:\"README.md\", contentType:\"file\"}.4, {\"name\":\"Research Question 2.docx\", path:\"Research Question 2.docx\", contentType:\"file\"}.5, {\"name\":\"Research question 1.docx\", path:\"Research question 1.docx\", contentType:\"file\"}.6, {\"name\":\"mirantis_repos.csv\", path:\"mirantis_repos.csv\", contentType:\"file\"}.7, {\"name\":\"mirantis_repos.txt\", path:\"mirantis_repos.txt\", contentType:\"file\"}.8, {\"name\":\"mozilla_repos.txt\", path:\"mozilla_repos.txt\", contentType:\"file\"}.9, {\"name\":\"opendev_repos.csv\", path:\"opendev_repos.csv\", contentType:\"file\"}.10, {\"name\":\"opendev_repos.txt\", path:\"opendev_repos.txt\", contentType:\"file\"}.11, {\"name\":\"replication_project.pdf\", path:\"replication_project.pdf\", contentType:\"file\"}].1, totalCount:12}}, fileTreeProcessingTime:5.573761, foldersToFetch:[], reducedMotionEnabled:\"system\", repo:{\"id\":699834996, defaultBranch:\"main\", name:\"Replication\", ownerLogin:\"GoodNightIsabel\", currentUserCanPush:true, isFork:false, isEmpty:false, createdAt:\"2023-10-03T08:43:59.000-04:00\", ownerAvatar:\"https://avatars.githubusercontent.com/u/64899589?v=4\", public:false, private:true, isOrgOwned:false}, symbolsExpanded:false, treeExpanded:true, refInfo:{\"name\":\"main\", listCacheKey:\"v0:1696534324.0\", canEdit:true, refType:\"branch\", currentOid:\"ab21a21fdbcbc82d2d0d556ad59d97ac578b9987\"}, path:\"datasets/IST_MIR.csv\".1, currentUser:{\"id\":88220339, login:\"GraciaKasereka\", userEmail:\"grakas243@gmail.com\"}, blob:{\"rawLines\":null, stylingDirectives:null, csv:[[\"org\", file_, URL, File, Lines_of_code, Require, Ensure, Include, Attribute, Hard_coded_string, Comment, Command, File_mode, SSH_KEY, defect_status], [\"MIRANTIS\", /Users/akond/PUPP_REPOS/mirantis-downloads/puppetlabs-openstack/manifests/db/mysql.pp, 0, ...]\n",
              "Index: []\n",
              "\n",
              "[0 rows x 2883 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-edc24cf8-6fb1-4cad-9c15-f911caee4f49\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>{\"payload\":{\"allShortcutsEnabled\":true</th>\n",
              "      <th>fileTree:{\"datasets\":{\"items\":[{\"name\":\"IST_MIR.csv\"</th>\n",
              "      <th>path:\"datasets/IST_MIR.csv\"</th>\n",
              "      <th>contentType:\"file\"}</th>\n",
              "      <th>{\"name\":\"IST_MOZ.csv\"</th>\n",
              "      <th>path:\"datasets/IST_MOZ.csv\"</th>\n",
              "      <th>contentType:\"file\"}.1</th>\n",
              "      <th>{\"name\":\"IST_OST.csv\"</th>\n",
              "      <th>path:\"datasets/IST_OST.csv\"</th>\n",
              "      <th>contentType:\"file\"}.2</th>\n",
              "      <th>...</th>\n",
              "      <th>orgHasCFBAccess:false</th>\n",
              "      <th>userHasCFIAccess:false</th>\n",
              "      <th>userHasOrgs:false</th>\n",
              "      <th>userIsOrgAdmin:false</th>\n",
              "      <th>userIsOrgMember:false</th>\n",
              "      <th>business:null</th>\n",
              "      <th>featureRequestInfo:null}}</th>\n",
              "      <th>csrf_tokens:{\"/GoodNightIsabel/Replication/branches\":{\"post\":\"X4-mtbStoBg42vx4kfnnkM4rlaQQj3fgbrG7leGvPahuhDoPakAmJCdh66jD7PlYbbW7pe2FnG_5E2achiz8rQ\"}</th>\n",
              "      <th>/repos/preferences:{\"post\":\"33NU-RjfTZGifSZCANEZ45PXKB70vIwpFaSj2JAljKFUAWYJPtAOiHTK7c9qqsDdYdoCqUKa2A40HwNHq1cKxA\"}}}</th>\n",
              "      <th>title:\"Replication/datasets/IST_MIR.csv at main · GoodNightIsabel/Replication\"}</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>0 rows × 2883 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edc24cf8-6fb1-4cad-9c15-f911caee4f49')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-edc24cf8-6fb1-4cad-9c15-f911caee4f49 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-edc24cf8-6fb1-4cad-9c15-f911caee4f49');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #log transformation on the extracted counts for each source code property\n",
        "log_transformed_Data1 = np.log1p(Data1)\n"
      ],
      "metadata": {
        "id": "3sJw6FKR8czZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the PCA\n",
        "pca = PCA(n_components=2)\n",
        "# Fit the PCA model to your data\n",
        "pca.fit(log_transformed_Data1)\n",
        "# Accessing the explained variance ratio\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained Variance Ratio:\", explained_variance)"
      ],
      "metadata": {
        "id": "uu-85bjpHNm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform data into the principal component space\n",
        "pca_data = pca.transform(log_transformed_Data1)"
      ],
      "metadata": {
        "id": "UUUZsAg2HcQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vizualization of the data\n",
        "# Scatter plot of the first two principal components\n",
        "plt.scatter(pca_data[:, 0], pca_data[:, 1])\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.title(\"PCA of Your Data\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PVjOoikUHrVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Classification and Regression Tree (CART): CART generates a tree based on the impurity measure, and uses that tree to provide de- cisions based on input features. We select CART because this learner does not make any assumption on the distribution of fea- tures, and is robust to model overfitting."
      ],
      "metadata": {
        "id": "pWjd6nlWJ78g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification and Regression Tree(CART)\n",
        "#Classification\n",
        "X=\n",
        "y=\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "#Regression\n",
        "# Import necessary libraries\n",
        "# Load the dataset\n",
        "data =\n",
        "X =\n",
        "y=\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor()\n",
        "\n",
        "# Fit the regressor on the training data\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Making predictions on the test data\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "# Evaluate the regressor using r2_score and mse\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n"
      ],
      "metadata": {
        "id": "WiOkpBAeH6Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNearestNeighbor(KNN):TheKNNclassificationtechniquestores all available prediction outcomes based on training data and classi- fies test data based on similarity measures. We select KNN because prior research has reported that defect prediction models that use KNN perform well"
      ],
      "metadata": {
        "id": "13b7RvJUKD8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the classification dataset\n",
        "data =\n",
        "X =\n",
        "y =\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a KNNClassifier\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "GZ7N8bZvJ6T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression (LR): LR estimates the probability that a data point belongs to a certain class, given the values of features. LR provides good performance for classification if the features are roughly linear. We select LR because this learner performs well for classification problems such as defect prediction and fault prediction."
      ],
      "metadata": {
        "id": "VAE7y-V-K2cL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the classification dataset\n",
        "data =\n",
        "X =\n",
        "y =\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "oZWy4C53Kvnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "• Naive Bayes (NB): The NB classification technique computes the posterior probability of each class to make prediction decisions. We select NB because prior research has reported that defect prediction models that use NB perform well"
      ],
      "metadata": {
        "id": "9o5uS_wCLgTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doing a Gaussian NB\n",
        "# Loading the classification dataset\n",
        "data =\n",
        "X =\n",
        "y =\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Creating a Gaussian Naive Bayes classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "SqYVcxb7L9se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest (RF): RF is an ensemble technique that creates mul- tiple classification trees, each of which are generated by taking ran- dom subsets of the training data. Unlike LR, RF does not ex- pect features to be linear for good classification performance. Re- searchers recommended the use of statistical learners that uses ensemble techniques to build defect prediction models."
      ],
      "metadata": {
        "id": "FLotM9jKMf7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#doing a Gaussian NB\n",
        "# Loading the classification dataset\n",
        "data =\n",
        "X =\n",
        "y =\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier with a specified number of trees (e.g., n_estimators=100)\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the classifier on the training data\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "qM_2MYXDMfiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing prediction performance using Scott-Knot"
      ],
      "metadata": {
        "id": "SYPfRQeFOyue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-posthocs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eq_7yTZO_hK",
        "outputId": "73d70097-55f2-446c-ce5f-04603e6cf779"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-posthocs in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.11.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (0.14.0)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (1.5.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (0.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from scikit-posthocs) (3.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->scikit-posthocs) (3.1.1)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels->scikit-posthocs) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels->scikit-posthocs) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scikit_posthocs import posthoc_sknofriedman"
      ],
      "metadata": {
        "id": "q6t_kNYPPJyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset with our performance measures, presicion,Recall,AUC and F-measure\n",
        "data = pd.DataFrame({\n",
        "    'Approach': ['Precision', 'Recall', 'AUC', 'F-Measure'],\n",
        "    'Precision': [0.85, 0.91, 0.87, 0.89],\n",
        "    'Recall': [0.92, 0.88, 0.90, 0.85],\n",
        "    'AUC': [0.94, 0.89, 0.93, 0.91],\n",
        "    'F-measure': [0.88, 0.89, 0.88, 0.88]\n",
        "})\n",
        "\n",
        "# Perform the Scott-Knott test for each performance measure\n",
        "precision_skn = posthoc_sknofriedman(data, val_col='Precision', group_col='Approach')\n",
        "recall_skn = posthoc_sknofriedman(data, val_col='Recall', group_col='Approach')\n",
        "auc_skn = posthoc_sknofriedman(data, val_col='AUC', group_col='Approach')\n",
        "f_measure_skn = posthoc_sknofriedman(data, val_col='F-measure', group_col='Approach')\n",
        "\n",
        "# Print the results\n",
        "print(\"Precision Scott-Knott:\")\n",
        "print(precision_skn)\n",
        "\n",
        "print(\"Recall Scott-Knott:\")\n",
        "print(recall_skn)\n",
        "\n",
        "print(\"AUC Scott-Knott:\")\n",
        "print(auc_skn)\n",
        "\n",
        "print(\"F-measure Scott-Knott:\")\n",
        "print(f_measure_skn)\n"
      ],
      "metadata": {
        "id": "FxVSvjtLPFEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation methods : We use 10 × 10-fold cross validation to evaluate our prediction mod- els."
      ],
      "metadata": {
        "id": "UfFFUZAcP3Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier  # need to replace with each model\n",
        "import numpy as np\n",
        "\n",
        "# Load your dataset and prepare features and target variables (X and y)\n",
        "\n",
        "# Define the model RandomForestClassifier,...\n",
        "model = RandomForestClassifier()\n",
        "# Define the outer cross-validation\n",
        "outer_cv = KFold(n_splits=10, shuffle=True, random_state=42) #can adjust the hyper parameter\n",
        "\n",
        "# Initializing a list to store the results from each run of the outer cv\n",
        "outer_results = []\n",
        "\n",
        "# Outer loop (10-fold cross-validation)\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Defining the inner cross-validation for hyperparameter tuning\n",
        "    inner_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    # Initializiing the list where we store the results from each run of the inner cross-validation\n",
        "    inner_results = []\n",
        "\n",
        "    # Inner loop (10-fold cross-validation for hyperparameter tuning)\n",
        "    for train_inner_index, val_index in inner_cv.split(X_train):\n",
        "        X_train_inner, X_val = X_train[train_inner_index], X_train[val_index]\n",
        "        y_train_inner, y_val = y_train[train_inner_index], y_train[val_index]\n",
        "\n",
        "        #selecting the best-performing Hyperparameters\n",
        "        #inner_performance\n",
        "\n",
        "    inner_results.append(inner_performance)\n",
        "\n",
        "    #  the best-performing hyperparameters/model based on inner validation results\n",
        "\n",
        "    # Fiting the selected model on the outer training data\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Here we evaluate the model on the outer test fold and record the performance\n",
        "    outer_performance = model.score(X_test, y_test)  # You can use any appropriate metric here\n",
        "\n",
        "    outer_results.append(outer_performance)\n",
        "\n",
        "# Calculating and printing the overall performance estimate from the outer cross-validation\n",
        "average_performance = np.mean(outer_results)\n",
        "print(\"Average Performance: {:.2f}%\".format(average_performance * 100))\n"
      ],
      "metadata": {
        "id": "DsTYjhZ7Pr-x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}